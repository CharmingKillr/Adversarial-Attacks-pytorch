{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-17T13:21:43.639277Z",
     "start_time": "2024-09-17T13:21:39.772935Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([3, 5]), tensor([2, 2]))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word embedding 以序列建模为例\n",
    "# 考虑source sentence 和 target sentence\n",
    "# 构建序列，序列的字符以其在词表中的索引的形式表示\n",
    "torch.manual_seed(1)\n",
    "batch_size = 2\n",
    "\n",
    "# 词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_embedding_dim = 8 #原文为512\n",
    "\n",
    "\n",
    "# 序列的最大长度   超参数 \n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "\n",
    "# 生成batch_size个句子的长度信息\n",
    "src_len = torch.randint(2, 6, (batch_size,))\n",
    "tgt_len = torch.randint(2, 6, (batch_size,))\n",
    "src_len,tgt_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:52:05.997615Z",
     "start_time": "2024-09-17T14:52:05.930186Z"
    }
   },
   "id": "22e1cbb210da4ab8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 7, 1, 0, 0],\n",
      "        [6, 1, 4, 5, 7]]) torch.Size([2, 5])\n",
      "tensor([[6, 6],\n",
      "        [3, 6]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 单词索引构成源句子和目标句子，构建batch, 做了padding， 默认值为0\n",
    "src_seq =[torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max(src_len)- L)), 0) \\\n",
    "          for L in src_len]\n",
    "tgt_seq =[torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max(tgt_len)- L)), 0) \\\n",
    "          for L in tgt_len]\n",
    "\n",
    "src_seq = torch.cat(src_seq, dim=0)\n",
    "tgt_seq = torch.cat(tgt_seq, dim=0)\n",
    "\n",
    "print(src_seq, src_seq.shape)\n",
    "print(tgt_seq, tgt_seq.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:52:09.742246Z",
     "start_time": "2024-09-17T14:52:09.716756Z"
    }
   },
   "id": "8e33be9552a62ff5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.8011, -1.5776, -0.9171, -0.2311,  1.0470, -1.5918,  0.0814,  1.0832],\n",
      "        [-0.5794, -0.5948,  0.0714,  0.3420,  0.8866, -0.8954,  0.1360,  0.6579],\n",
      "        [-0.9102, -0.1423,  0.2989,  1.4571,  0.2304, -0.1479, -0.6358,  0.3535],\n",
      "        [-0.0321, -0.5684, -1.4244, -1.3247, -2.0823, -0.6323,  1.5993,  1.9342],\n",
      "        [ 0.5931,  1.8194, -0.8792, -1.1781,  0.2504,  0.3679, -0.5098, -0.0992],\n",
      "        [-0.5083,  1.2397,  0.4237,  0.2669,  0.0768, -1.0789,  0.7933, -0.6170],\n",
      "        [-1.5175, -1.0135,  1.3760,  1.4397, -2.2479,  1.3209, -0.5391,  0.3898],\n",
      "        [ 1.3822, -1.0321,  0.7139, -1.5632, -0.3591, -0.8194,  1.6901,  0.2580],\n",
      "        [-0.0032,  0.1425,  0.9438, -0.2258,  0.4633, -1.6465, -0.8888,  1.7225]],\n",
      "       requires_grad=True)\n",
      "tensor([[[-1.5175, -1.0135,  1.3760,  1.4397, -2.2479,  1.3209, -0.5391,\n",
      "           0.3898],\n",
      "         [-1.5175, -1.0135,  1.3760,  1.4397, -2.2479,  1.3209, -0.5391,\n",
      "           0.3898]],\n",
      "\n",
      "        [[-0.0321, -0.5684, -1.4244, -1.3247, -2.0823, -0.6323,  1.5993,\n",
      "           1.9342],\n",
      "         [-1.5175, -1.0135,  1.3760,  1.4397, -2.2479,  1.3209, -0.5391,\n",
      "           0.3898]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造word embedding \n",
    "src_embedding_table = nn.Embedding(max_num_src_words + 1, model_embedding_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words + 1, model_embedding_dim)\n",
    "print(tgt_embedding_table.weight)\n",
    "\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "print(tgt_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:53:57.859810Z",
     "start_time": "2024-09-17T14:53:57.839066Z"
    }
   },
   "id": "56fb88e0e419f98b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 构造position embedding\n",
    "pos_mat = torch.arange(max_position_len).reshape(-1, 1)\n",
    "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape(1, -1) / model_embedding_dim)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_embedding_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat / i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat / i_mat)\n",
    "\n",
    "# 位置索引\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)), 0) for _ in src_len])\n",
    "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)), 0) for _ in src_len])\n",
    "\n",
    "pe_embedding = nn.Embedding(max_position_len, model_embedding_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "\n",
    "src_pe_embedding = pe_embedding(src_pos)\n",
    "tgt_pe_embedding = pe_embedding(tgt_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T14:52:16.607274Z",
     "start_time": "2024-09-17T14:52:16.592037Z"
    }
   },
   "id": "d1e3d3e9dbda0bf5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[   1.,   10.,  100., 1000.]]),\n tensor([[0],\n         [1],\n         [2],\n         [3],\n         [4]]),\n tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03],\n         [2.0000e+00, 2.0000e-01, 2.0000e-02, 2.0000e-03],\n         [3.0000e+00, 3.0000e-01, 3.0000e-02, 3.0000e-03],\n         [4.0000e+00, 4.0000e-01, 4.0000e-02, 4.0000e-03]]),\n Parameter containing:\n tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00],\n         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00],\n         [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n           9.9920e-01,  4.0000e-03,  9.9999e-01]]),\n tensor([[0, 1, 2, 3, 4],\n         [0, 1, 2, 3, 4]]),\n tensor([[0, 1],\n         [0, 1]]),\n tensor([[[0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n           1.0000e+00, 0.0000e+00, 1.0000e+00],\n          [8.4147e-01, 5.4030e-01, 9.9833e-02, 9.9500e-01, 9.9998e-03,\n           9.9995e-01, 1.0000e-03, 1.0000e+00]],\n \n         [[0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n           1.0000e+00, 0.0000e+00, 1.0000e+00],\n          [8.4147e-01, 5.4030e-01, 9.9833e-02, 9.9500e-01, 9.9998e-03,\n           9.9995e-01, 1.0000e-03, 1.0000e+00]]]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_mat , pos_mat, pos_mat / i_mat, pe_embedding.weight, src_pos, tgt_pos, tgt_pe_embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T11:59:58.552365Z",
     "start_time": "2024-09-14T11:59:58.530362Z"
    }
   },
   "id": "fe1db550fccbb06c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "tensor([[[False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "# 构造encoder的self-attention mask\n",
    "# mask的shape: [batch_size, max_src_len, max_src_len],值为1或为-inf\n",
    "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) \\\n",
    "                               for L in src_len]), 2)\n",
    "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1, 2))\n",
    "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "\n",
    "print(invalid_encoder_pos_matrix)\n",
    "print(mask_encoder_self_attention)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T13:16:11.910131Z",
     "start_time": "2024-09-14T13:16:11.893728Z"
    }
   },
   "id": "b465e00af17c60e",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0757, -0.5536, -1.6160,  0.0934, -1.3898],\n",
      "         [-0.3105,  1.0693,  1.4394,  1.3694,  0.4539],\n",
      "         [-0.0498,  0.3745,  1.4389,  1.4151, -0.1589],\n",
      "         [-0.7360, -2.0311, -1.1064,  0.1879,  0.1146],\n",
      "         [ 1.1904,  0.5201, -0.3884, -0.0316, -1.1085]],\n",
      "\n",
      "        [[-1.8874, -0.0863,  1.4791,  0.9428, -0.1244],\n",
      "         [-1.5083, -0.7200,  0.7923, -0.3385,  1.4161],\n",
      "         [ 0.4738,  0.0827, -1.3034,  0.5190,  1.3395],\n",
      "         [-0.2388, -0.0680,  1.1349,  0.8658,  0.6334],\n",
      "         [-0.5392,  0.0182,  1.4142, -1.7438,  0.1129]]])\n",
      "tensor([[[ 1.0757e+00, -5.5361e-01, -1.6160e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [-3.1046e-01,  1.0693e+00,  1.4394e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [-4.9785e-02,  3.7450e-01,  1.4389e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[-1.8874e+00, -8.6326e-02,  1.4791e+00,  9.4282e-01, -1.2443e-01],\n",
      "         [-1.5083e+00, -7.1996e-01,  7.9233e-01, -3.3846e-01,  1.4161e+00],\n",
      "         [ 4.7376e-01,  8.2703e-02, -1.3034e+00,  5.1899e-01,  1.3395e+00],\n",
      "         [-2.3876e-01, -6.7961e-02,  1.1349e+00,  8.6577e-01,  6.3335e-01],\n",
      "         [-5.3920e-01,  1.8176e-02,  1.4142e+00, -1.7438e+00,  1.1289e-01]]])\n",
      "tensor([[[0.7912, 0.1551, 0.0536, 0.0000, 0.0000],\n",
      "         [0.0932, 0.3704, 0.5363, 0.0000, 0.0000],\n",
      "         [0.1437, 0.2196, 0.6367, 0.0000, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]],\n",
      "\n",
      "        [[0.0170, 0.1030, 0.4927, 0.2882, 0.0991],\n",
      "         [0.0286, 0.0628, 0.2850, 0.0920, 0.5317],\n",
      "         [0.1898, 0.1284, 0.0321, 0.1986, 0.4511],\n",
      "         [0.0866, 0.1027, 0.3421, 0.2614, 0.2072],\n",
      "         [0.0832, 0.1453, 0.5868, 0.0249, 0.1597]]])\n"
     ]
    }
   ],
   "source": [
    "# score = torch.randn(batch_size, max(src_len), max(src_len))\n",
    "# \n",
    "# masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
    "# prob = torch.softmax(masked_score, dim=-1)\n",
    "# \n",
    "# print(score)\n",
    "# print(masked_score)\n",
    "# print(prob)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T13:21:29.756349Z",
     "start_time": "2024-09-14T13:21:29.745827Z"
    }
   },
   "id": "a5d4c75fcb3ad10d",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # scaled的重要性\n",
    "# alpha1 = 0.1\n",
    "# alpha2 = 10\n",
    "# score = torch.randn(5)\n",
    "# prob1 = F.softmax(score*alpha1, dim=-1)\n",
    "# prob2 = F.softmax(score*alpha2, dim=-1)\n",
    "# print(score)\n",
    "# print(prob1, prob2)\n",
    "# \n",
    "# def softmax_func(score):\n",
    "#     return F.softmax(score, dim=-1)\n",
    "# \n",
    "# jaco_mat1 = torch.autograd.functional.jacobian(softmax_func, score*alpha1)\n",
    "# jaco_mat2 = torch.autograd.functional.jacobian(softmax_func, score*alpha2)\n",
    "# print(jaco_mat1)\n",
    "# print(jaco_mat2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T12:01:27.661279Z",
     "start_time": "2024-09-14T12:01:27.646828Z"
    }
   },
   "id": "4c22caed1a96a334",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Transformer(batch_first=True)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-17T16:03:51.512974Z",
     "start_time": "2024-09-17T16:03:51.267225Z"
    }
   },
   "id": "6ad878476906cc2d",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
